{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up The Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Local machine detected\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "import sys\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "from io import StringIO\n",
    "import traceback\n",
    "\n",
    "import optuna\n",
    "import torch\n",
    "from optuna.storages import JournalStorage, JournalFileStorage\n",
    "import yaml\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "except ImportError:\n",
    "    logging.info(\"Local machine detected\")\n",
    "    sys.path.append(os.path.realpath(\"..\"))\n",
    "else:\n",
    "    logging.info(\"Colab detected\")\n",
    "    drive.mount(\"/content/drive\")\n",
    "    sys.path.append(\"/content/drive/MyDrive/ecg-reconstruction/src\")\n",
    "\n",
    "from ecg.trainer import Trainer, TrainerConfig\n",
    "from ecg.reconstructor.cnn.cnn import StackedCNN\n",
    "from ecg.reconstructor.transformer.transformer import UFormer, NaiveTransformerEncoder\n",
    "from ecg.reconstructor.transformer.fastformer import Fastformer, UFastformer\n",
    "from ecg.reconstructor.lstm.lstm import LSTM, CNNLSTM\n",
    "from ecg.util.device import get_device\n",
    "from ecg.util.tree import deep_merge\n",
    "from ecg.util.path import get_project_root_dir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Model With a Suggested Set of Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_experiment(\n",
    "    trial: optuna.Trial, \n",
    "    base_config: TrainerConfig,\n",
    "    tuning_dir: Path,\n",
    ") -> Optional[float]:\n",
    "    \"\"\"\n",
    "    This is the main function for optuna to tune a model.\n",
    "    \"\"\"\n",
    "    reconstructor_type = base_config[\"reconstructor\"][\"type\"]\n",
    "    config = deep_merge(base_config, reconstructor_type.suggest_config(trial))\n",
    "\n",
    "    # The followings are the configs after tuning.\n",
    "    config[\"optimizer\"][\"args\"] = {\n",
    "        \"lr\": trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 5e-6, 5e-2, log=True),\n",
    "    }\n",
    "    if config[\"optimizer\"][\"type\"] == \"AdamW\":\n",
    "        config[\"optimizer\"][\"args\"][\"betas\"] = [\n",
    "            trial.suggest_float(\"b1\", 0.85, 0.95, log=True),\n",
    "            trial.suggest_float(\"b2\", 0.950, 0.9999, log=True),\n",
    "        ]\n",
    "\n",
    "    config[\"lr_scheduler\"] = {}\n",
    "    scheduler_type = config[\"lr_scheduler\"][\"type\"] = trial.suggest_categorical(\n",
    "        \"type\", [\"CosineAnnealingWarmRestarts\", \"ReduceLROnPlateau\"]\n",
    "    )\n",
    "    if scheduler_type == \"ReduceLROnPlateau\":\n",
    "        config[\"lr_scheduler\"][\"args\"] = {\n",
    "            \"factor\": trial.suggest_float(\"factor\", 0.2, 0.8),\n",
    "            \"patience\": trial.suggest_int(\"patience\", 2, 5),\n",
    "        }\n",
    "    elif scheduler_type == \"CosineAnnealingWarmRestarts\":\n",
    "        config[\"lr_scheduler\"][\"args\"] = {\n",
    "            \"T_0\": trial.suggest_int(\"T_0\", 1, 4),\n",
    "            \"T_mult\": 1,\n",
    "        }\n",
    "\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [128, 256, 512])\n",
    "    config[\"dataloader\"][\"common\"][\"batch_size\"] = batch_size\n",
    "    # to avoide OOM\n",
    "    config[\"accumulate_grad_batches\"] = max(1, batch_size // reconstructor_type.max_batch_size)\n",
    "\n",
    "    config_stream = StringIO()\n",
    "    yaml.dump(config, config_stream, yaml.Dumper, indent=4)\n",
    "    logging.info(\"Config:\\n%s\", config_stream.getvalue())\n",
    "    \n",
    "    config_to_log = config.copy()\n",
    "    del config_to_log[\"reconstructor\"]\n",
    "    logging.info(json.dumps(config_to_log, indent=4))\n",
    "    trainer = Trainer(config)\n",
    "    tuning_config_dir = tuning_dir / f\"trial_{trial.number}\"\n",
    "    with tuning_config_dir.open(\"w\", encoding=\"utf-8\") as config_file:\n",
    "            yaml.dump(trainer.config, config_file, Dumper=yaml.Dumper)\n",
    "    try:\n",
    "        loss = trainer.fit(trial=trial)\n",
    "    except RuntimeError:\n",
    "        error_stream = StringIO()\n",
    "        traceback.print_exc(file=error_stream)\n",
    "        logging.error(\"Training failed\\n%s\", error_stream.getvalue())\n",
    "        loss = None\n",
    "    del trainer\n",
    "    if get_device().type == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "    return loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning The Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sonne\\AppData\\Local\\Temp\\ipykernel_20152\\2465949478.py:37: ExperimentalWarning: JournalStorage is experimental (supported from v3.1.0). The interface can change in the future.\n",
      "  storage = JournalStorage(JournalFileStorage(str(tuning_dir / f\"{experiment_name}.log\")))\n",
      "[I 2023-07-18 12:15:27,077] A new study created in Journal with name: tuning_logs_StackedCNN\n",
      "INFO:root:Config:\n",
      "accumulate_grad_batches: 8\n",
      "dataloader:\n",
      "    common:\n",
      "        batch_size: 128\n",
      "        num_workers: 6\n",
      "dataset:\n",
      "    common:\n",
      "        feature_scaling: false\n",
      "        filter_args:\n",
      "            N: 3\n",
      "            Wn: !!python/tuple\n",
      "            - 0.5\n",
      "            - 60\n",
      "            btype: bandpass\n",
      "        filter_type: butter\n",
      "        include_filtered_signal: false\n",
      "        include_labels: {}\n",
      "        include_original_signal: false\n",
      "        mean_normalization: true\n",
      "        predicate: null\n",
      "        signal_dtype: float32\n",
      "    eval:\n",
      "        hdf5_filename: ptb-xl/validation.hdf5\n",
      "    train:\n",
      "        hdf5_filename: ptb-xl/train.hdf5\n",
      "in_leads:\n",
      "- 0\n",
      "- 1\n",
      "- 8\n",
      "lr_scheduler:\n",
      "    args:\n",
      "        T_0: 4\n",
      "        T_mult: 1\n",
      "    type: CosineAnnealingWarmRestarts\n",
      "max_epochs: 8\n",
      "optimizer:\n",
      "    args:\n",
      "        betas:\n",
      "        - 0.9498901251449483\n",
      "        - 0.9676524085383224\n",
      "        lr: 0.0001895114455717707\n",
      "        weight_decay: 0.03425142358950694\n",
      "    type: AdamW\n",
      "out_leads:\n",
      "- 6\n",
      "- 7\n",
      "- 9\n",
      "- 10\n",
      "- 11\n",
      "reconstructor:\n",
      "    args:\n",
      "        base_channels: 48\n",
      "        dilation_scale: 3\n",
      "        kernel_size: 31\n",
      "        num_layers: 3\n",
      "    type: !!python/name:ecg.reconstructor.cnn.cnn.StackedCNN ''\n",
      "\n",
      "INFO:root:{\n",
      "    \"optimizer\": {\n",
      "        \"type\": \"AdamW\",\n",
      "        \"args\": {\n",
      "            \"lr\": 0.0001895114455717707,\n",
      "            \"weight_decay\": 0.03425142358950694,\n",
      "            \"betas\": [\n",
      "                0.9498901251449483,\n",
      "                0.9676524085383224\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"lr_scheduler\": {\n",
      "        \"type\": \"CosineAnnealingWarmRestarts\",\n",
      "        \"args\": {\n",
      "            \"T_0\": 4,\n",
      "            \"T_mult\": 1\n",
      "        }\n",
      "    },\n",
      "    \"accumulate_grad_batches\": 8,\n",
      "    \"dataloader\": {\n",
      "        \"common\": {\n",
      "            \"num_workers\": 6,\n",
      "            \"batch_size\": 128\n",
      "        }\n",
      "    },\n",
      "    \"max_epochs\": 8,\n",
      "    \"dataset\": {\n",
      "        \"common\": {\n",
      "            \"predicate\": null,\n",
      "            \"signal_dtype\": \"float32\",\n",
      "            \"filter_type\": \"butter\",\n",
      "            \"filter_args\": {\n",
      "                \"N\": 3,\n",
      "                \"Wn\": [\n",
      "                    0.5,\n",
      "                    60\n",
      "                ],\n",
      "                \"btype\": \"bandpass\"\n",
      "            },\n",
      "            \"mean_normalization\": true,\n",
      "            \"feature_scaling\": false,\n",
      "            \"include_original_signal\": false,\n",
      "            \"include_filtered_signal\": false,\n",
      "            \"include_labels\": {}\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"hdf5_filename\": \"ptb-xl/train.hdf5\"\n",
      "        },\n",
      "        \"eval\": {\n",
      "            \"hdf5_filename\": \"ptb-xl/validation.hdf5\"\n",
      "        }\n",
      "    },\n",
      "    \"in_leads\": [\n",
      "        0,\n",
      "        1,\n",
      "        8\n",
      "    ],\n",
      "    \"out_leads\": [\n",
      "        6,\n",
      "        7,\n",
      "        9,\n",
      "        10,\n",
      "        11\n",
      "    ]\n",
      "}\n",
      "[W 2023-07-18 12:15:27,189] Trial 0 failed with parameters: {'num_layers': 3, 'base_channels': 48, 'kernel_size': 31, 'dilation_scale': 3, 'lr': 0.0001895114455717707, 'weight_decay': 0.03425142358950694, 'b1': 0.9498901251449483, 'b2': 0.9676524085383224, 'type': 'CosineAnnealingWarmRestarts', 'T_0': 4, 'batch_size': 128} because of the following error: TypeError(\"StackedCNN.__init__() got an unexpected keyword argument 'kernel_size'\").\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\MyApps\\Anaconda\\envs\\ecg-reconstruction\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\sonne\\AppData\\Local\\Temp\\ipykernel_20152\\2456206079.py\", line 50, in train_experiment\n",
      "    trainer = Trainer(config)\n",
      "  File \"D:\\Desktop\\ECG Reconstruction\\ecg-reconstruction\\src\\ecg\\trainer.py\", line 81, in __init__\n",
      "    self._create_reconstructor()\n",
      "  File \"D:\\Desktop\\ECG Reconstruction\\ecg-reconstruction\\src\\ecg\\trainer.py\", line 492, in _create_reconstructor\n",
      "    self.reconstructor = reconstructor_type(\n",
      "TypeError: StackedCNN.__init__() got an unexpected keyword argument 'kernel_size'\n",
      "[W 2023-07-18 12:15:27,190] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "StackedCNN.__init__() got an unexpected keyword argument 'kernel_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 54\u001b[0m\n\u001b[0;32m     44\u001b[0m     study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(\n\u001b[0;32m     45\u001b[0m         direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     46\u001b[0m         storage\u001b[39m=\u001b[39mstorage,  \u001b[39m# Specify the storage URL here.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m         load_if_exists\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     50\u001b[0m     )\n\u001b[0;32m     51\u001b[0m trial_function \u001b[39m=\u001b[39m partial(\n\u001b[0;32m     52\u001b[0m     train_experiment, base_config\u001b[39m=\u001b[39mbase_config, tuning_dir\u001b[39m=\u001b[39mtuning_dir\n\u001b[0;32m     53\u001b[0m )\n\u001b[1;32m---> 54\u001b[0m study\u001b[39m.\u001b[39;49moptimize(trial_function, n_trials\u001b[39m=\u001b[39;49mn_trials)\n\u001b[0;32m     55\u001b[0m best_number \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mbest_trial\u001b[39m.\u001b[39mnumber\n\u001b[0;32m     56\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(tuning_dir \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbest_trial\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n",
      "File \u001b[1;32md:\\MyApps\\Anaconda\\envs\\ecg-reconstruction\\lib\\site-packages\\optuna\\study\\study.py:443\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[0;32m    340\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    341\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    349\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    350\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \n\u001b[0;32m    352\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 443\u001b[0m     _optimize(\n\u001b[0;32m    444\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    445\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    446\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    447\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    448\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    449\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[0;32m    450\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    451\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    452\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    453\u001b[0m     )\n",
      "File \u001b[1;32md:\\MyApps\\Anaconda\\envs\\ecg-reconstruction\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32md:\\MyApps\\Anaconda\\envs\\ecg-reconstruction\\lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32md:\\MyApps\\Anaconda\\envs\\ecg-reconstruction\\lib\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32md:\\MyApps\\Anaconda\\envs\\ecg-reconstruction\\lib\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[2], line 50\u001b[0m, in \u001b[0;36mtrain_experiment\u001b[1;34m(trial, base_config, tuning_dir)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[39mdel\u001b[39;00m config_to_log[\u001b[39m\"\u001b[39m\u001b[39mreconstructor\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     49\u001b[0m logging\u001b[39m.\u001b[39minfo(json\u001b[39m.\u001b[39mdumps(config_to_log, indent\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m))\n\u001b[1;32m---> 50\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(config)\n\u001b[0;32m     51\u001b[0m tuning_config_dir \u001b[39m=\u001b[39m tuning_dir \u001b[39m/\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrial_\u001b[39m\u001b[39m{\u001b[39;00mtrial\u001b[39m.\u001b[39mnumber\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     52\u001b[0m \u001b[39mwith\u001b[39;00m tuning_config_dir\u001b[39m.\u001b[39mopen(\u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m config_file:\n",
      "File \u001b[1;32mD:\\Desktop\\ECG Reconstruction\\ecg-reconstruction\\src\\ecg\\trainer.py:81\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_dataloaders()\n\u001b[0;32m     80\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreconstructor: Reconstructor \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m---> 81\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_reconstructor()\n\u001b[0;32m     82\u001b[0m lead_names \u001b[39m=\u001b[39m get_lead_names()\n\u001b[0;32m     83\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Desktop\\ECG Reconstruction\\ecg-reconstruction\\src\\ecg\\trainer.py:492\u001b[0m, in \u001b[0;36mTrainer._create_reconstructor\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    488\u001b[0m reconstructor_type \u001b[39m=\u001b[39m Reconstructor\u001b[39m.\u001b[39mresolve_type(\n\u001b[0;32m    489\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39mreconstructor\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    490\u001b[0m )\n\u001b[0;32m    491\u001b[0m _logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mCreate the reconstruction model\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 492\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreconstructor \u001b[39m=\u001b[39m reconstructor_type(\n\u001b[0;32m    493\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\n\u001b[0;32m    494\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39min_leads\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39min_leads\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m    495\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mout_leads\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39mout_leads\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m    496\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39mreconstructor\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m    497\u001b[0m     },\n\u001b[0;32m    498\u001b[0m )\n\u001b[0;32m    499\u001b[0m device \u001b[39m=\u001b[39m get_device()\n\u001b[0;32m    500\u001b[0m _logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mMove the reconstruction model to \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, device)\n",
      "\u001b[1;31mTypeError\u001b[0m: StackedCNN.__init__() got an unexpected keyword argument 'kernel_size'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# MODEL_TYPE = NaiveTransformerEncoder\n",
    "MODEL_TYPE = StackedCNN\n",
    "dataset_name = \"ptb-xl\"\n",
    "trial_epochs = 8\n",
    "n_trials = 50\n",
    "\n",
    "base_config: TrainerConfig = {\n",
    "    \"in_leads\": [0, 1, 8],\n",
    "    \"out_leads\": [6, 7, 9, 10, 11],\n",
    "    \"max_epochs\": trial_epochs,\n",
    "    \"accumulate_grad_batches\": 1,\n",
    "    \"dataset\": {\n",
    "        \"common\": {\n",
    "            # \"predicate\": \"lambda f: f['SB'][:]\",\n",
    "            \"predicate\": None,\n",
    "            \"signal_dtype\": \"float32\",\n",
    "            \"filter_type\": \"butter\",\n",
    "            \"filter_args\": {\"N\": 3, \"Wn\": (0.5, 60), \"btype\": \"bandpass\"},\n",
    "            \"mean_normalization\": True,\n",
    "            \"feature_scaling\": False,\n",
    "            \"include_original_signal\": False,\n",
    "            \"include_filtered_signal\": False,\n",
    "            \"include_labels\": {},\n",
    "        },\n",
    "        \"train\": {\"hdf5_filename\": f\"{dataset_name}/train.hdf5\"},\n",
    "        \"eval\": {\"hdf5_filename\": f\"{dataset_name}/validation.hdf5\"},\n",
    "    },\n",
    "    \"dataloader\": {\n",
    "        \"common\": {\"num_workers\": 6},\n",
    "    },\n",
    "    \"reconstructor\": {\"type\": MODEL_TYPE},\n",
    "}\n",
    "\n",
    "tuning_dir = get_project_root_dir() / \"src\" / \"tuning\" / MODEL_TYPE.__name__\n",
    "tuning_dir.mkdir(exist_ok=True, parents=True)\n",
    "experiment_name = f\"tuning_logs_{MODEL_TYPE.__name__}\"\n",
    "storage = JournalStorage(JournalFileStorage(str(tuning_dir / f\"{experiment_name}.log\")))\n",
    "try:\n",
    "    study = optuna.load_study(\n",
    "        storage=storage,\n",
    "        study_name=experiment_name,\n",
    "    )\n",
    "except:\n",
    "    study = optuna.create_study(\n",
    "        direction=\"minimize\",\n",
    "        storage=storage,  # Specify the storage URL here.\n",
    "        study_name=experiment_name,\n",
    "        pruner=optuna.pruners.MedianPruner(),\n",
    "        load_if_exists=True,\n",
    "    )\n",
    "trial_function = partial(\n",
    "    train_experiment, base_config=base_config, tuning_dir=tuning_dir\n",
    ")\n",
    "study.optimize(trial_function, n_trials=n_trials)\n",
    "best_number = study.best_trial.number\n",
    "with open(tuning_dir / \"best_trial\", \"w\") as f:\n",
    "    f.write(f\"{best_number}\")\n",
    "study.best_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg-reconstruction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "-1.-1.-1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
