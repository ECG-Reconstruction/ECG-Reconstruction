{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup The Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Local machine detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import yaml\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "except ImportError:\n",
    "    logging.info(\"Local machine detected\")\n",
    "    sys.path.append(os.path.realpath(\"..\"))\n",
    "else:\n",
    "    logging.info(\"Colab detected\")\n",
    "    drive.mount(\"/content/drive\")\n",
    "    sys.path.append(\"/content/drive/MyDrive/ecg-reconstruction/src\")\n",
    "\n",
    "from ecg.trainer import Trainer, TrainerConfig\n",
    "from ecg.reconstructor.transformer.transformer import UFormer\n",
    "from ecg.reconstructor.lstm.lstm import LSTM\n",
    "from ecg.reconstructor.linear.linear import Linear\n",
    "from ecg.util.tree import deep_merge"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Model With a New Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36757449b8dd4296842bda1b0c7bdb87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ecg.trainer:Epoch 1\n",
      "Train 769/769 [0:00:42<0:00:00, 0.0545s/it, batch_loss=0.07923, average_loss=0.09844]\n",
      "INFO:ecg.trainer:Loss=0.09844, RMSE=0.3137, Pearson-R=0.7595\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 42\u001b[0m\n\u001b[0;32m     40\u001b[0m config[\u001b[39m\"\u001b[39m\u001b[39maccumulate_grad_batches\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     41\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(config)\n\u001b[1;32m---> 42\u001b[0m trainer\u001b[39m.\u001b[39;49mfit()\n",
      "File \u001b[1;32mD:\\Desktop\\ECG Reconstruction\\ecg-reconstruction\\src\\ecg\\trainer.py:227\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, name, tensorboard, checkpoint, log_every_n_steps, trial)\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mlog_epoch(train_writer, global_step)\n\u001b[0;32m    220\u001b[0m _logger\u001b[39m.\u001b[39minfo(\n\u001b[0;32m    221\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mLoss=\u001b[39m\u001b[39m%.4g\u001b[39;00m\u001b[39m, RMSE=\u001b[39m\u001b[39m%.4g\u001b[39;00m\u001b[39m, Pearson-R=\u001b[39m\u001b[39m%.4g\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39maverage_loss\u001b[39m.\u001b[39mget_average(),\n\u001b[0;32m    223\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mrmse\u001b[39m.\u001b[39mget_average(),\n\u001b[0;32m    224\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mpearson_r\u001b[39m.\u001b[39mget_average(),\n\u001b[0;32m    225\u001b[0m )\n\u001b[1;32m--> 227\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_eval_impl(epoch, progress_prefix\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mEvaluation\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    228\u001b[0m average_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39maverage_loss\u001b[39m.\u001b[39mget_average()\n\u001b[0;32m    229\u001b[0m _logger\u001b[39m.\u001b[39minfo(\n\u001b[0;32m    230\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mLoss=\u001b[39m\u001b[39m%.4g\u001b[39;00m\u001b[39m, RMSE=\u001b[39m\u001b[39m%.4g\u001b[39;00m\u001b[39m, PearsonR=\u001b[39m\u001b[39m%.4g\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    231\u001b[0m     average_loss,\n\u001b[0;32m    232\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mrmse\u001b[39m.\u001b[39mget_average(),\n\u001b[0;32m    233\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mpearson_r\u001b[39m.\u001b[39mget_average(),\n\u001b[0;32m    234\u001b[0m )\n",
      "File \u001b[1;32mD:\\Desktop\\ECG Reconstruction\\ecg-reconstruction\\src\\ecg\\trainer.py:278\u001b[0m, in \u001b[0;36mTrainer._eval_impl\u001b[1;34m(self, epoch, progress_prefix)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreconstructor\u001b[39m.\u001b[39meval()\n\u001b[0;32m    277\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mreset(epoch)\n\u001b[1;32m--> 278\u001b[0m counter \u001b[39m=\u001b[39m ProgressCounter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meval_dataloader, prefix\u001b[39m=\u001b[39;49mprogress_prefix)\n\u001b[0;32m    279\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m    280\u001b[0m     \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m counter:\n",
      "File \u001b[1;32mD:\\Desktop\\ECG Reconstruction\\ecg-reconstruction\\src\\ecg\\util\\progress.py:39\u001b[0m, in \u001b[0;36mProgressCounter.__init__\u001b[1;34m(self, iterable, prefix, length, stream)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[39mInitializes the progress counter.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[39m    stream: The stream to print the progress counter to.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_length \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(iterable) \u001b[39mif\u001b[39;00m length \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m length\n\u001b[1;32m---> 39\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator \u001b[39m=\u001b[39m \u001b[39miter\u001b[39;49m(iterable)\n\u001b[0;32m     40\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prefix \u001b[39m=\u001b[39m prefix\n\u001b[0;32m     41\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stream \u001b[39m=\u001b[39m stream\n",
      "File \u001b[1;32md:\\MyApps\\Anaconda\\envs\\ecg-reconstruction\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:436\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpersistent_workers \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_workers \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    435\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 436\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n\u001b[0;32m    437\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\u001b[39m.\u001b[39m_reset(\u001b[39mself\u001b[39m)\n",
      "File \u001b[1;32md:\\MyApps\\Anaconda\\envs\\ecg-reconstruction\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32md:\\MyApps\\Anaconda\\envs\\ecg-reconstruction\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1042\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1035\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1042\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1043\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32md:\\MyApps\\Anaconda\\envs\\ecg-reconstruction\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32md:\\MyApps\\Anaconda\\envs\\ecg-reconstruction\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32md:\\MyApps\\Anaconda\\envs\\ecg-reconstruction\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32md:\\MyApps\\Anaconda\\envs\\ecg-reconstruction\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32md:\\MyApps\\Anaconda\\envs\\ecg-reconstruction\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "MODEL_TYPE = Linear\n",
    "# dataset = \"ptb-xl\"\n",
    "dataset = \"code15%\"\n",
    "\n",
    "for i in tqdm(range(6, 12)):\n",
    "    config: TrainerConfig = {\n",
    "        \"in_leads\": [0, 1, i],\n",
    "        \"out_leads\": [oidx for oidx in range(6, 12) if oidx != i],\n",
    "        \"max_epochs\": 32,\n",
    "        \"accumulate_grad_batches\": 8,\n",
    "        \"dataset\": {\n",
    "            \"common\": {\n",
    "                \"predicate\": None,\n",
    "                \"signal_dtype\": \"float32\",\n",
    "                \"filter_type\": \"butter\",\n",
    "                \"filter_args\": {\"N\": 3, \"Wn\": (0.5, 60), \"btype\": \"bandpass\"},\n",
    "                # \"filter_args\": {\"N\": 3, \"Wn\": (0.05, 150), \"btype\": \"bandpass\"},\n",
    "                # \"mean_normalization\": True,\n",
    "                \"mean_normalization\": False,\n",
    "                \"feature_scaling\": False,\n",
    "                \"include_original_signal\": False,\n",
    "                \"include_filtered_signal\": False, # This will be set to True in visulization\n",
    "                \"include_labels\": {},\n",
    "            },\n",
    "            \"train\": {\"hdf5_filename\": f\"{dataset}/train.hdf5\"},\n",
    "            \"eval\": {\"hdf5_filename\": f\"{dataset}/validation.hdf5\"},\n",
    "        },\n",
    "        \"dataloader\": {\n",
    "            \"common\": {\"num_workers\": 6},\n",
    "        },\n",
    "        \"reconstructor\": {\"type\": MODEL_TYPE},\n",
    "    }\n",
    "    # with open(os.path.join(f\"../best_configs/{MODEL_TYPE.__name__}/tuned_config.yaml\"), 'r') as fp:\n",
    "    #     best_config = yaml.safe_load(fp)\n",
    "\n",
    "    config = deep_merge(config, MODEL_TYPE.default_config())\n",
    "    config['reconstructor'][\"args\"]['in_leads'] = config['in_leads']\n",
    "    config['reconstructor'][\"args\"]['out_leads'] = config['out_leads']\n",
    "    config['dataloader']['common'][\"batch_size\"] = 256\n",
    "    config[\"accumulate_grad_batches\"] = 1\n",
    "    trainer = Trainer(config)\n",
    "    trainer.fit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model\n",
    "This is a simple test. For more complicated analysis, please refer to [`testing notebook`](./src/notebooks/demo_testing_and_visualize.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef044d3ec1f4b1e8da66f187766d4fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test 165/165 [0:00:07<0:00:00, 0.0433s/it, batch_loss=0.1539, average_loss=0.09478] \n",
      "INFO:root:Loss: 0.094779\n",
      "INFO:root:RMSE: 0.307862\n",
      "INFO:root:PearsonR: 0.776552\n",
      "Test 165/165 [0:00:07<0:00:00, 0.0427s/it, batch_loss=0.1051, average_loss=0.07003] \n",
      "INFO:root:Loss: 0.070032\n",
      "INFO:root:RMSE: 0.264636\n",
      "INFO:root:PearsonR: 0.823635\n",
      "Test 165/165 [0:00:07<0:00:00, 0.04s/it, batch_loss=0.08826, average_loss=0.0628]   \n",
      "INFO:root:Loss: 0.062797\n",
      "INFO:root:RMSE: 0.250593\n",
      "INFO:root:PearsonR: 0.835283\n",
      "Test 165/165 [0:00:06<0:00:00, 0.036s/it, batch_loss=0.1068, average_loss=0.07961]  \n",
      "INFO:root:Loss: 0.079608\n",
      "INFO:root:RMSE: 0.282149\n",
      "INFO:root:PearsonR: 0.758198\n",
      "Test 165/165 [0:00:06<0:00:00, 0.0384s/it, batch_loss=0.1601, average_loss=0.1041]  \n",
      "INFO:root:Loss: 0.104052\n",
      "INFO:root:RMSE: 0.322570\n",
      "INFO:root:PearsonR: 0.600485\n",
      "Test 165/165 [0:00:06<0:00:00, 0.0364s/it, batch_loss=0.204, average_loss=0.1316]  \n",
      "INFO:root:Loss: 0.131649\n",
      "INFO:root:RMSE: 0.362834\n",
      "INFO:root:PearsonR: 0.474759\n"
     ]
    }
   ],
   "source": [
    "checkpoint_dir = Path(\"../checkpoints/Linear\")\n",
    "\n",
    "# checkpoint_dir /= (checkpoint_dir / \"latest\").read_text().strip()\n",
    "subfolders = [ Path(f.path) for f in os.scandir(checkpoint_dir) if f.is_dir() ]\n",
    "for checkpoint in tqdm(subfolders):\n",
    "    with open( checkpoint / \"trainer_config.yaml\", encoding=\"utf-8\") as config_file:\n",
    "        config = yaml.load(config_file, Loader=yaml.Loader)\n",
    "    \n",
    "    config['dataset']['eval']['hdf5_filename'] = 'code15%/test.hdf5'\n",
    "\n",
    "    trainer = Trainer(config)\n",
    "    trainer.load_checkpoint(checkpoint / (checkpoint / \"best\").read_text().strip())\n",
    "    trainer.test()\n",
    "    logging.info(\"Loss: %f\", trainer.metrics.average_loss.get_average())\n",
    "    logging.info(\"RMSE: %f\", trainer.metrics.rmse.get_average())\n",
    "    logging.info(\"PearsonR: %f\", trainer.metrics.pearson_r.get_average())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg-reconstruction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "-1.-1.-1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
